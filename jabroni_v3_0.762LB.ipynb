{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jabroni_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "StPRPtW_NCTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ]
    },
    {
      "metadata": {
        "id": "DnkZYdj6MM3A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install imageio\n",
        "! pip install kaggle\n",
        "! pip install ipywidgets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWfNVpqgNJ9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import"
      ]
    },
    {
      "metadata": {
        "id": "n1rakkMNL5ZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, BatchNormalization, Activation, UpSampling2D, ZeroPadding2D\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Cropping2D\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras import optimizers\n",
        "\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zK52VZqtNL1c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper Classes"
      ]
    },
    {
      "metadata": {
        "id": "YebzzJQiMFji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert rle to mask image\n",
        "def rleToMask(rleString,height,width):\n",
        "    rows,cols = height,width\n",
        "    try:\n",
        "        #get numbers\n",
        "        rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n",
        "        #get pairs\n",
        "        rlePairs = np.array(rleNumbers).reshape(-1,2)\n",
        "        #create an image\n",
        "        img = np.zeros(rows*cols,dtype=np.uint8)\n",
        "        #for each pair\n",
        "        for index,length in rlePairs:\n",
        "            #get the pixel value \n",
        "            index -= 1\n",
        "            img[index:index+length] = 255\n",
        "        #reshape\n",
        "        img = img.reshape(cols,rows)\n",
        "        img = img.T    \n",
        "    #else return empty image\n",
        "    except:\n",
        "        img = np.zeros((cols,rows))\n",
        "    return img\n",
        "\n",
        "# resize predicted mask to original size  \n",
        "def resize_mask(x):\n",
        "  resized_mask = resize(x, (101, 101, 1), mode='constant', preserve_range=True)\n",
        "  return resized_mask\n",
        "\n",
        "# binarize the output probabilities  \n",
        "def binarize(x, threshold):\n",
        "  bz = np.where(x>threshold, 1, 0)\n",
        "  return bz\n",
        "\n",
        "# encode predicted mask to rle \n",
        "def run_length_encoding(x):\n",
        "    # https://www.kaggle.com/c/data-science-bowl-2018/discussion/48561#\n",
        "    bs = np.where(x.T.flatten())[0]\n",
        "    rle = []\n",
        "    prev = -2\n",
        "    for b in bs:\n",
        "        if (b > prev + 1):\n",
        "            rle.extend((b + 1, 0))\n",
        "        rle[-1] += 1\n",
        "        prev = b\n",
        "    return rle\n",
        "\n",
        "# generate submission dataframe\n",
        "def create_submission(metalist, predictions):\n",
        "    output = []\n",
        "    for image_id, mask in zip(metalist, predictions):\n",
        "        resized_mask = resize_mask(mask)\n",
        "        bz_mask = binarize(resized_mask, 0.5)\n",
        "        rle_encoded = ' '.join(str(rle) for rle in run_length_encoding(bz_mask))\n",
        "        output.append([image_id, rle_encoded])\n",
        "\n",
        "    submission = pd.DataFrame(output, columns=['id', 'rle_mask']).astype(str)\n",
        "    return submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbL7BrC9MiBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_size = 128\n",
        "def upsample(imglist):\n",
        "  outlist = []\n",
        "  for img in imglist:\n",
        "    res = np.stack([img for i in range(3)], axis = -1)\n",
        "    res = resize(res, (target_size, target_size), mode='constant', preserve_range=True) \n",
        "    outlist.append(res)\n",
        "  return outlist\n",
        "\n",
        "def upsample_mask(imglist):\n",
        "  outlist = []\n",
        "  for img in imglist:\n",
        "    res = resize(img, (target_size, target_size), mode='constant', preserve_range=True) \n",
        "    outlist.append(res)\n",
        "  return outlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StKo-ohGrcCz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper function to print status of layers (trainable/non-trainable)"
      ]
    },
    {
      "metadata": {
        "id": "Y1C90xTIrbQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_layer_trainable(model):\n",
        "    for layer in model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qVNintQZNOJG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "metadata": {
        "id": "_FURYM2fMUIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZOMdnUvM2pN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ensure its there\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YnKCzGsvM8m7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wox9M90RM-iN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#lets now download our dataset\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jemc97zLNAyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#and we'll need those training images unzipped\n",
        "!ls\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_L5iIv9zXCcR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip test.zip -d test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcOm4mNoNke3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialize"
      ]
    },
    {
      "metadata": {
        "id": "jDzNltqAN2aM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBEJU5bZNhWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\", index_col=\"id\", usecols=[0])\n",
        "depths_df = pd.read_csv(\"depths.csv\", index_col=\"id\")\n",
        "train_df = train_df.join(depths_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0v10iZtuN5Zj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"images\"] = [np.array(load_img(\"images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zSDrVF3UOa_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"masks\"] = [np.array(load_img(\"masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spDNxZ5AMBlE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Salt coverage stratification"
      ]
    },
    {
      "metadata": {
        "id": "P7UdMrG2MElE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(101, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fARc9m14MH2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cov_to_class(val):    \n",
        "    for i in range(0, 11):\n",
        "        if val * 10 <= i :\n",
        "            return i\n",
        "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFYnr00sewkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = upsample(train_df.images.values.tolist()) \n",
        "X = np.array(X).reshape(-1, 128, 128, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFtWbN_ggO44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = upsample_mask(train_df.masks.values.tolist())\n",
        "Y = np.array(Y).reshape(-1, 128, 128, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRxW9pzuMPKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_valid, depth_train, depth_valid = train_test_split(\n",
        "    train_df.index.values,\n",
        "    X,\n",
        "    Y,\n",
        "    train_df.coverage.values,\n",
        "    train_df.z.values,\n",
        "    test_size=0.10, stratify=train_df.coverage_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POspvyTREfLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "EXE-VhFWBBRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_datagen = image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "mask_datagen = image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "# Provide the same seed and keyword arguments to the fit and flow methods\n",
        "seed = 1\n",
        "\n",
        "image_datagen.fit(x_train, augment=True, seed=seed)\n",
        "mask_datagen.fit(y_train, augment=True, seed=seed)\n",
        "\n",
        "x_generator = image_datagen.flow(x_train,depth_train,batch_size=16,seed=seed)\n",
        "y_generator = mask_datagen.flow(y_train,batch_size=16,seed=seed)\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "train_generator = zip(x_generator, y_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svQFcS0FOFP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build ResNet50+UNet model"
      ]
    },
    {
      "metadata": {
        "id": "bBujaaDvC5db",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ResNet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1S2XxJMNVEe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ResNet50.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DIV91De8t---",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Merge layers"
      ]
    },
    {
      "metadata": {
        "id": "V4mRGsXsktkU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transfer_layers = [ResNet50.get_layer('conv1_pad'), ResNet50.get_layer('activation_1'), ResNet50.get_layer('activation_10'), ResNet50.get_layer('activation_22'), ResNet50.get_layer('activation_40'), ResNet50.get_layer('activation_49')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "986W_X02pSAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(transfer_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lWH1GUoVkGff",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for l in transfer_layers:\n",
        "  print(l.output.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIquTUfsiD02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_width = 128\n",
        "im_height = 128\n",
        "\n",
        "im_chan = 3 \n",
        "n_features = 1 # Number of extra features, like depth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVnHwXxrmDf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet50 = Model(inputs=ResNet50.input, outputs=[transfer_layers[i].output for i in range(6)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDdSAj13pMfv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initial architecture\n",
        "input_img = Input((im_height, im_width, im_chan), name='img')\n",
        "input_features = Input((n_features, ), name='feat')\n",
        "up_0 = UpSampling2D()(input_img)\n",
        "Resnet = resnet50(up_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6z5_TA1r746x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Write Unet portion"
      ]
    },
    {
      "metadata": {
        "id": "M9CgW6Fs73MR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Join features information in the deepest layer\n",
        "f_repeat = RepeatVector(8*8)(input_features)\n",
        "f_conv = Reshape((8, 8, n_features))(f_repeat)\n",
        "p4_feat = concatenate([Resnet[5], f_conv], -1)\n",
        "\n",
        "# 8x8\n",
        "u6 = Conv2DTranspose(1024, (2, 2), strides=(2, 2), padding='same') (p4_feat)\n",
        "b6 = BatchNormalization()(u6)\n",
        "# 16x16\n",
        "u6 = concatenate([u6, Resnet[4]])\n",
        "c6 = Conv2D(1024, (3, 3), activation='relu', padding='same') (u6)\n",
        "b6 = BatchNormalization()(c6)\n",
        "c6 = Conv2D(1024, (3, 3), activation='relu', padding='same') (b6)\n",
        "b6 = BatchNormalization()(c6)\n",
        "\n",
        "u7 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "b7 = BatchNormalization()(u7)\n",
        "# 32x32\n",
        "u7 = concatenate([u7, Resnet[3]])\n",
        "c7 = Conv2D(512, (3, 3), activation='relu', padding='same') (u7)\n",
        "b7 = BatchNormalization()(c7)\n",
        "c7 = Conv2D(512, (3, 3), activation='relu', padding='same') (b7)\n",
        "b7 = BatchNormalization()(c7)\n",
        "\n",
        "\n",
        "u8 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "b8 = BatchNormalization()(u8)\n",
        "# 64x64\n",
        "###### adjustment 63x63\n",
        "up8 = UpSampling2D()(b8)\n",
        "cr8 = Cropping2D(cropping=(1,1)) (up8)\n",
        "a8 = AveragePooling2D()(cr8)\n",
        "######\n",
        "u8 = concatenate([a8, Resnet[2]])\n",
        "###### again 64x64\n",
        "up8 = UpSampling2D()(u8)\n",
        "z8 = ZeroPadding2D()(up8)\n",
        "a8 = AveragePooling2D()(z8)\n",
        "######\n",
        "c8 = Conv2D(256, (3, 3), activation='relu', padding='same') (a8)\n",
        "b8 = BatchNormalization()(c8)\n",
        "c8 = Conv2D(256, (3, 3), activation='relu', padding=('same')) (c8)\n",
        "b8 = BatchNormalization()(c8)\n",
        "\n",
        "u9 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "b9 = BatchNormalization()(u9)\n",
        "# 128x128\n",
        "u9 = concatenate([u9, Resnet[1]], axis=3)\n",
        "c9 = Conv2D(128, (3, 3), activation='relu', padding='same') (b9)\n",
        "b9 = BatchNormalization()(c9)\n",
        "c9 = Conv2D(128, (3, 3), activation='relu', padding='same') (b9)\n",
        "b9 = BatchNormalization()(c9)\n",
        "'''\n",
        "u10 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c9)\n",
        "# 256x256\n",
        "###### adjustment 262x262\n",
        "z10 = ZeroPadding2D(padding=(3, 3))(u10)\n",
        "######\n",
        "u10 = concatenate([z10, Resnet[0]], axis=3)\n",
        "c10 = Conv2D(64, (3, 3), activation='relu', padding='valid') (u10)\n",
        "c10 = Conv2D(64, (3, 3), activation='relu', padding='valid') (c10)\n",
        "c10 = Conv2D(64, (3, 3), activation='relu', padding='valid') (c10)\n",
        "'''\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (b9)\n",
        "\n",
        "model = Model(inputs=[input_img, input_features], outputs=[outputs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBZ3kboQqhS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARYcM1UH8F8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the layers by name\n",
        "for i,layer in enumerate(model.layers):\n",
        "    print(i,layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "271VdC5Sst3q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "metadata": {
        "id": "awsNwldgtUFW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "metadata": {
        "id": "m760KCWfTf7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10azs3Pxsagb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_layer_trainable(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gMyhuzmLq2E9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once we have changed whether the model's layers are trainable, we need to compile the model for the changes to take effect."
      ]
    },
    {
      "metadata": {
        "id": "sj_r17Bddc5Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Lower learning rate**"
      ]
    },
    {
      "metadata": {
        "id": "kTYBH0ymTf7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer_fine = optimizers.Adam(lr=1e-4)\n",
        "loss = 'binary_crossentropy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpVpikLHTf7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer_fine, loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghYIOzAyYCXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "3_tomVkwNN6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(patience=3, verbose=1),\n",
        "    ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]\n",
        "\n",
        "results = model.fit(generator{'img': x_train, 'feat': depth_train}, y_train, batch_size=16, epochs=25, callbacks=callbacks,\n",
        "                    validation_data=({'img': x_valid, 'feat': depth_valid}, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXKRmnpRaMJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load model from saved weights (if runtime dies)"
      ]
    },
    {
      "metadata": {
        "id": "AosZu0tNaJdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.load_weights('model-tgs-salt-1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rG7y_rqlXvra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess testing data"
      ]
    },
    {
      "metadata": {
        "id": "Sopk8B1pXwA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_ids = next(os.walk(\"test/images\"))[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WhKsFDs7cwpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.float32)\n",
        "X_test_feat = np.zeros((len(test_ids), n_features), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCxzneuBf0JY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting and resizing test images... \n",
        "for n, ID in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    # depth feature\n",
        "    X_test_feat[n] = depths_df.loc[ID.replace('.png', ''), 'z']\n",
        "    # Load X\n",
        "    img = [np.array(load_img(\"test/images/\" + ID, grayscale=True))/255]\n",
        "    x_img = upsample(img)[0]\n",
        "    X_test[n] = np.array(x_img).reshape(128, 128, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35W-7Z9YWBRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ]
    },
    {
      "metadata": {
        "id": "QG-E7K_3V_kK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outputs = model.predict({'img': X_test, 'feat': X_test_feat}, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HPF2zFyYtCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create csv and submit to kaggle"
      ]
    },
    {
      "metadata": {
        "id": "aIPuG-3kYw_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(test_ids)):\n",
        "  test_ids[i] = test_ids[i][:-4]\n",
        "\n",
        "submission = create_submission(test_ids, outputs)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xIpw-QtoY4nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c tgs-salt-identification-challenge -f submission.csv -m \"Trial submission\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}